{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN53efefOajCzK6IW44euwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaibhavs10/notebooks/blob/main/insanely_fast_whisper_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Insanely Fast Whisper](https://github.com/Vaibhavs10/insanely-fast-whisper)\n",
        "\n",
        "By VB (https://twitter.com/reach_vb)\n",
        "\n",
        "P.S. Make sure you're on a GPU run-time ğŸ¤—"
      ],
      "metadata": {
        "id": "q0MBgZKbhdII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pipx && apt install python3.10-venv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF-qp-FWJmyD",
        "outputId": "e174fade-6f07-4097-a52a-3d0e32664bdb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/57.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 9 not upgraded.\n",
            "Need to get 2,473 kB of archives.\n",
            "After this operation, 2,884 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.4 [1,680 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-setuptools-whl all 59.6.0-1.2ubuntu0.22.04.1 [788 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.2 [5,724 B]\n",
            "Fetched 2,473 kB in 1s (2,865 kB/s)\n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "(Reading database ... 120880 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.2_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.2) ...\n",
            "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.2) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pipx run insanely-fast-whisper --file-name https://huggingface.co/datasets/reach-vb/random-audios/resolve/main/ted_60.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_H9Dm89Jj0-",
        "outputId": "9a3d6ce5-8988-4397-f5d2-e1f1b8b4714a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json: 100% 1.25k/1.25k [00:00<00:00, 7.59MB/s]\n",
            "model.safetensors: 100% 3.09G/3.09G [00:17<00:00, 173MB/s]\n",
            "generation_config.json: 100% 3.87k/3.87k [00:00<00:00, 18.9MB/s]\n",
            "tokenizer_config.json: 100% 283k/283k [00:00<00:00, 10.7MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 5.26MB/s]\n",
            "tokenizer.json: 100% 2.48M/2.48M [00:00<00:00, 28.3MB/s]\n",
            "merges.txt: 100% 494k/494k [00:00<00:00, 28.3MB/s]\n",
            "normalizer.json: 100% 52.7k/52.7k [00:00<00:00, 175MB/s]\n",
            "added_tokens.json: 100% 34.6k/34.6k [00:00<00:00, 42.8MB/s]\n",
            "special_tokens_map.json: 100% 2.07k/2.07k [00:00<00:00, 11.2MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "preprocessor_config.json: 100% 340/340 [00:00<00:00, 1.96MB/s]\n",
            "The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n",
            "\u001b[2KğŸ¤— \u001b[33mTranscribing...\u001b[0m \u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[93mâ”\u001b[0m \u001b[33m0:00:09\u001b[0m\n",
            "\u001b[?25hVoila! Your file has been transcribed go check it out over here! output.json\n"
          ]
        }
      ]
    }
  ]
}